{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Deep Reinforcement Learning Connect 4",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SurekaStoeckigt/DeepReinforcementLearning/blob/master/Copy_of_Deep_Reinforcement_Learning_Connect_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5p5qS-MrmVv4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Deep Reinforcement Learning using AlphaZero methodology\n",
        "Please see https://applied-data.science/blog/how-to-build-your-own-alphazero-ai-using-python-and-keras/ for further notes on the codebase"
      ]
    },
    {
      "metadata": {
        "id": "65VxSSVmlv8X",
        "colab_type": "code",
        "outputId": "aca94d47-459c-4390-8bd5-7b0c2d592e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4458
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf DeepReinforcementLearning\n",
        "!git clone https://github.com/AppliedDataSciencePartners/DeepReinforcementLearning.git\n",
        "!pip install -r ./DeepReinforcementLearning/requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepReinforcementLearning'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Total 168 (delta 0), reused 0 (delta 0), pack-reused 168\u001b[K\n",
            "Receiving objects: 100% (168/168), 2.64 MiB | 18.63 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "Collecting absl-py==0.1.12 (from -r ./DeepReinforcementLearning/requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/53/cd8524308bb662bb8493ff140c76d329f6e88742e5cd18ee9b3f090ff60d/absl-py-0.1.12.tar.gz (79kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 3.2MB/s \n",
            "\u001b[?25hCollecting appnope==0.1.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 2))\n",
            "  Downloading https://files.pythonhosted.org/packages/87/a9/7985e6a53402f294c8f0e8eff3151a83f1fb901fa92909bb3ff29b4d22af/appnope-0.1.0-py2.py3-none-any.whl\n",
            "Collecting astor==0.6.2 (from -r ./DeepReinforcementLearning/requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/91/cc9805f1ff7b49f620136b3a7ca26f6a1be2ed424606804b0fbcf499f712/astor-0.6.2-py2.py3-none-any.whl\n",
            "Collecting bleach==1.5.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 5)) (0.10.0)\n",
            "Collecting decorator==4.2.1 (from -r ./DeepReinforcementLearning/requirements.txt (line 6))\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/5a/53db15bf367d2028bdc6700dbdf1bdfab46b9f208b7516952817c0808118/decorator-4.2.1-py2.py3-none-any.whl\n",
            "Collecting gast==0.2.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 7))\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
            "Collecting graphviz==0.8.2 (from -r ./DeepReinforcementLearning/requirements.txt (line 8))\n",
            "  Downloading https://files.pythonhosted.org/packages/05/e4/8fcc76823534d47f079c0ff1b3d8b57784e8fba63ceb1ded32c9f4dd993c/graphviz-0.8.2-py2.py3-none-any.whl\n",
            "Collecting grpcio==1.10.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/ec/a32bb323eeb32236d2faa7876231225c40fba12771c50a44880155e80c20/grpcio-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (7.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 7.5MB 3.3MB/s \n",
            "\u001b[?25hCollecting h5py==2.7.1 (from -r ./DeepReinforcementLearning/requirements.txt (line 10))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/b8/a63fcc840bba5c76e453dd712dbca63178a264c8990e0086b72965d4e954/h5py-2.7.1-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.4MB 8.0MB/s \n",
            "\u001b[?25hCollecting html5lib==0.9999999 (from -r ./DeepReinforcementLearning/requirements.txt (line 11))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K    100% |████████████████████████████████| 890kB 20.2MB/s \n",
            "\u001b[?25hCollecting ipykernel==4.8.2 (from -r ./DeepReinforcementLearning/requirements.txt (line 12))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/3f/cd624c835aa3336a9110d0a99e15070f343b881b7d651ab1375ef226a3ac/ipykernel-4.8.2-py3-none-any.whl (108kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 33.0MB/s \n",
            "\u001b[?25hCollecting ipython==6.2.1 (from -r ./DeepReinforcementLearning/requirements.txt (line 13))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/87/294b718125085559b56453be87d90777863173470167e5f1d5de20b9eea3/ipython-6.2.1-py3-none-any.whl (745kB)\n",
            "\u001b[K    100% |████████████████████████████████| 747kB 21.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 14)) (0.2.0)\n",
            "Collecting jedi==0.11.1 (from -r ./DeepReinforcementLearning/requirements.txt (line 15))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ca/d71f5a427601c98eadabfd73104cacbec8cc230e8416158decf61a48b0c6/jedi-0.11.1-py2.py3-none-any.whl (250kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 26.9MB/s \n",
            "\u001b[?25hCollecting jupyter-client==5.2.3 (from -r ./DeepReinforcementLearning/requirements.txt (line 16))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/dd/fe6c4d683b09eb05342bd2816b7779663f71762b4fa9c2d5203d35d17354/jupyter_client-5.2.3-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core==4.4.0 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 17)) (4.4.0)\n",
            "Collecting Keras==2.1.5 (from -r ./DeepReinforcementLearning/requirements.txt (line 18))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
            "\u001b[K    100% |████████████████████████████████| 337kB 28.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 19)) (1.0.1)\n",
            "Collecting Markdown==2.6.11 (from -r ./DeepReinforcementLearning/requirements.txt (line 20))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 27.2MB/s \n",
            "\u001b[?25hCollecting matplotlib==2.2.2 (from -r ./DeepReinforcementLearning/requirements.txt (line 21))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/b8/89dbd27f2fb171ce753bb56220d4d4f6dbc5fe32b95d8edc4415782ef07f/matplotlib-2.2.2-cp36-cp36m-manylinux1_x86_64.whl (12.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.6MB 3.1MB/s \n",
            "\u001b[?25hCollecting numpy==1.14.2 (from -r ./DeepReinforcementLearning/requirements.txt (line 22))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/dc/92c0f670e7b986829fc92c4c0208edb9d72908149da38ecda50d816ea057/numpy-1.14.2-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.2MB 2.1MB/s \n",
            "\u001b[?25hCollecting parso==0.1.1 (from -r ./DeepReinforcementLearning/requirements.txt (line 23))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/2f/96f54499c920070ccc1bffaee115a6a0cf1a0e7ece34b8faa7ee632688dd/parso-0.1.1-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 29.1MB/s \n",
            "\u001b[?25hCollecting pexpect==4.4.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 24))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/80/3a8f823aadc85a8ba3744d95ba591cbe999fbca5d97429a056fd82c4ea92/pexpect-4.4.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 24.5MB/s \n",
            "\u001b[?25hCollecting pickleshare==0.7.4 (from -r ./DeepReinforcementLearning/requirements.txt (line 25))\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/17/daa142fc9be6b76f26f24eeeb9a138940671490b91cb5587393f297c8317/pickleshare-0.7.4-py2.py3-none-any.whl\n",
            "Collecting prompt-toolkit==1.0.15 (from -r ./DeepReinforcementLearning/requirements.txt (line 26))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/c6616dd03701e7e2073f06d5c3b41b012256e42b72561f16a7bd86dd7b43/prompt_toolkit-1.0.15-py3-none-any.whl (247kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 18.5MB/s \n",
            "\u001b[?25hCollecting protobuf==3.5.2.post1 (from -r ./DeepReinforcementLearning/requirements.txt (line 27))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/ad/ecd865eb1ba1ff7f6bd6bcb731a89d55bc0450ced8d457ed2d167c7b8d5f/protobuf-3.5.2.post1-cp36-cp36m-manylinux1_x86_64.whl (6.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 6.4MB 6.9MB/s \n",
            "\u001b[?25hCollecting ptyprocess==0.5.2 (from -r ./DeepReinforcementLearning/requirements.txt (line 28))\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/4e/fa4a73ccfefe2b37d7b6898329e7dbcd1ac846ba3a3b26b294a78a3eb997/ptyprocess-0.5.2-py2.py3-none-any.whl\n",
            "Collecting pydot==1.2.4 (from -r ./DeepReinforcementLearning/requirements.txt (line 29))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/f1/e61d6dfe6c1768ed2529761a68f70939e2569da043e9f15a8d84bf56cadf/pydot-1.2.4.tar.gz (132kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 34.7MB/s \n",
            "\u001b[?25hCollecting pydot-ng==1.0.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 30))\n",
            "  Downloading https://files.pythonhosted.org/packages/de/64/86b0502c3644190c0b9fed0e378ee18f31b1f0262bdead1eb9ac1d404529/pydot_ng-1.0.0.tar.gz\n",
            "Collecting Pygments==2.2.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 31))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/ee/b6e02dc6529e82b75bb06823ff7d005b141037cb1416b10c6f00fc419dca/Pygments-2.2.0-py2.py3-none-any.whl (841kB)\n",
            "\u001b[K    100% |████████████████████████████████| 849kB 23.9MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.2.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 32))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/8a/718fd7d3458f9fab8e67186b00abdd345b639976bc7fb3ae722e1b026a50/pyparsing-2.2.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 24.8MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.7.1 (from -r ./DeepReinforcementLearning/requirements.txt (line 33))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/27/d6be8938e2cd9c956c2c6c0b3253e1c62d6db29a52b477943da3c3ec728c/python_dateutil-2.7.1-py2.py3-none-any.whl (212kB)\n",
            "\u001b[K    100% |████████████████████████████████| 215kB 31.8MB/s \n",
            "\u001b[?25hCollecting pytz==2018.3 (from -r ./DeepReinforcementLearning/requirements.txt (line 34))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/80/32e98784a8647880dedf1f6bf8e2c91b195fe18fdecc6767dcf5104598d6/pytz-2018.3-py2.py3-none-any.whl (509kB)\n",
            "\u001b[K    100% |████████████████████████████████| 512kB 23.2MB/s \n",
            "\u001b[?25hCollecting PyYAML==3.12 (from -r ./DeepReinforcementLearning/requirements.txt (line 35))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/85/db5a2df477072b2902b0eb892feb37d88ac635d36245a72a6a69b23b383a/PyYAML-3.12.tar.gz (253kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq==17.0.0 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 36)) (17.0.0)\n",
            "Collecting scipy==1.0.1 (from -r ./DeepReinforcementLearning/requirements.txt (line 37))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/13/eb888fcc83f14d114dee794c3491477ce156caa9f456b7bef1112dde36b5/scipy-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 50.0MB 723kB/s \n",
            "\u001b[?25hRequirement already satisfied: simplegeneric==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 38)) (0.8.1)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 39)) (1.11.0)\n",
            "Collecting tensorboard==1.6.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 40))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/67/a8c91665987d359211dcdca5c8b2a7c1e0876eb0702a4383c1e4ff76228d/tensorboard-1.6.0-py3-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.1MB 12.5MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.6.0 (from -r ./DeepReinforcementLearning/requirements.txt (line 41))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/0f/fbd8bb92459c75db93040f80702ebe4ba83a52cdb6ad930654c31dc0b711/tensorflow-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (45.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 45.9MB 872kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 42)) (1.1.0)\n",
            "Collecting tornado==5.0.1 (from -r ./DeepReinforcementLearning/requirements.txt (line 43))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/60/5b34caa5014eb3f1deb16d0e72cc08abeec7a9c9823486da7984ddadc95f/tornado-5.0.1.tar.gz (504kB)\n",
            "\u001b[K    100% |████████████████████████████████| 512kB 20.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets==4.3.2 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 44)) (4.3.2)\n",
            "Requirement already satisfied: wcwidth==0.1.7 in /usr/local/lib/python3.6/dist-packages (from -r ./DeepReinforcementLearning/requirements.txt (line 45)) (0.1.7)\n",
            "Collecting Werkzeug==0.14.1 (from -r ./DeepReinforcementLearning/requirements.txt (line 46))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
            "\u001b[K    100% |████████████████████████████████| 327kB 22.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython==6.2.1->-r ./DeepReinforcementLearning/requirements.txt (line 13)) (40.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.6.0->-r ./DeepReinforcementLearning/requirements.txt (line 40)) (0.33.1)\n",
            "Building wheels for collected packages: absl-py, gast, html5lib, pydot, pydot-ng, PyYAML, tornado\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f3/6d/ce/98cfc871c5846580a58a0167483395a24b2728ab6770fcc218\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "  Building wheel for pydot (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6a/a5/14/25541ebcdeaf97a37b6d05c7ff15f5bd20f5e91b99d313e5b4\n",
            "  Building wheel for pydot-ng (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ef/d1/b6/e2b937c79d99d49b7db9233832a425c7e6b787486f5831b302\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/03/05/65/bdc14f2c6e09e82ae3e0f13d021e1b6b2481437ea2f207df3f\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/09/6b/dd/9c4fa388872cddb7e88ee7c457d2213c65ae74b8099cb4c5ca\n",
            "Successfully built absl-py gast html5lib pydot pydot-ng PyYAML tornado\n",
            "\u001b[31mtfds-nightly 1.0.2.dev201904090105 has requirement protobuf>=3.6.1, but you'll have protobuf 3.5.2.post1 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow-metadata 0.13.0 has requirement protobuf<4,>=3.7, but you'll have protobuf 3.5.2.post1 which is incompatible.\u001b[0m\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mnetworkx 2.3 has requirement decorator>=4.3.0, but you'll have decorator 4.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mmagenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogleapis-common-protos 1.5.9 has requirement protobuf>=3.6.0, but you'll have protobuf 3.5.2.post1 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement ipykernel~=4.6.0, but you'll have ipykernel 4.8.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 6.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement tornado~=4.5.0, but you'll have tornado 5.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.51 has requirement numpy>=1.15, but you'll have numpy 1.14.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mdopamine-rl 1.0.5 has requirement absl-py>=0.2.2, but you'll have absl-py 0.1.12 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mcvxpy 1.0.15 has requirement scipy>=1.1.0, but you'll have scipy 1.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: absl-py, appnope, astor, html5lib, bleach, decorator, gast, graphviz, protobuf, grpcio, numpy, h5py, ptyprocess, pexpect, prompt-toolkit, pickleshare, parso, jedi, Pygments, ipython, python-dateutil, tornado, jupyter-client, ipykernel, scipy, PyYAML, Keras, Markdown, pyparsing, pytz, matplotlib, pydot, pydot-ng, Werkzeug, tensorboard, tensorflow\n",
            "  Found existing installation: absl-py 0.7.1\n",
            "    Uninstalling absl-py-0.7.1:\n",
            "      Successfully uninstalled absl-py-0.7.1\n",
            "  Found existing installation: astor 0.7.1\n",
            "    Uninstalling astor-0.7.1:\n",
            "      Successfully uninstalled astor-0.7.1\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.0\n",
            "    Uninstalling bleach-3.1.0:\n",
            "      Successfully uninstalled bleach-3.1.0\n",
            "  Found existing installation: decorator 4.4.0\n",
            "    Uninstalling decorator-4.4.0:\n",
            "      Successfully uninstalled decorator-4.4.0\n",
            "  Found existing installation: gast 0.2.2\n",
            "    Uninstalling gast-0.2.2:\n",
            "      Successfully uninstalled gast-0.2.2\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Found existing installation: protobuf 3.7.1\n",
            "    Uninstalling protobuf-3.7.1:\n",
            "      Successfully uninstalled protobuf-3.7.1\n",
            "  Found existing installation: grpcio 1.15.0\n",
            "    Uninstalling grpcio-1.15.0:\n",
            "      Successfully uninstalled grpcio-1.15.0\n",
            "  Found existing installation: numpy 1.16.2\n",
            "    Uninstalling numpy-1.16.2:\n",
            "      Successfully uninstalled numpy-1.16.2\n",
            "  Found existing installation: h5py 2.8.0\n",
            "    Uninstalling h5py-2.8.0:\n",
            "      Successfully uninstalled h5py-2.8.0\n",
            "  Found existing installation: ptyprocess 0.6.0\n",
            "    Uninstalling ptyprocess-0.6.0:\n",
            "      Successfully uninstalled ptyprocess-0.6.0\n",
            "  Found existing installation: pexpect 4.7.0\n",
            "    Uninstalling pexpect-4.7.0:\n",
            "      Successfully uninstalled pexpect-4.7.0\n",
            "  Found existing installation: prompt-toolkit 1.0.16\n",
            "    Uninstalling prompt-toolkit-1.0.16:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.16\n",
            "  Found existing installation: pickleshare 0.7.5\n",
            "    Uninstalling pickleshare-0.7.5:\n",
            "      Successfully uninstalled pickleshare-0.7.5\n",
            "  Found existing installation: parso 0.4.0\n",
            "    Uninstalling parso-0.4.0:\n",
            "      Successfully uninstalled parso-0.4.0\n",
            "  Found existing installation: jedi 0.13.3\n",
            "    Uninstalling jedi-0.13.3:\n",
            "      Successfully uninstalled jedi-0.13.3\n",
            "  Found existing installation: Pygments 2.1.3\n",
            "    Uninstalling Pygments-2.1.3:\n",
            "      Successfully uninstalled Pygments-2.1.3\n",
            "  Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Found existing installation: python-dateutil 2.5.3\n",
            "    Uninstalling python-dateutil-2.5.3:\n",
            "      Successfully uninstalled python-dateutil-2.5.3\n",
            "  Found existing installation: tornado 4.5.3\n",
            "    Uninstalling tornado-4.5.3:\n",
            "      Successfully uninstalled tornado-4.5.3\n",
            "  Found existing installation: jupyter-client 5.2.4\n",
            "    Uninstalling jupyter-client-5.2.4:\n",
            "      Successfully uninstalled jupyter-client-5.2.4\n",
            "  Found existing installation: ipykernel 4.6.1\n",
            "    Uninstalling ipykernel-4.6.1:\n",
            "      Successfully uninstalled ipykernel-4.6.1\n",
            "  Found existing installation: scipy 1.2.1\n",
            "    Uninstalling scipy-1.2.1:\n",
            "      Successfully uninstalled scipy-1.2.1\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "  Found existing installation: Markdown 3.1\n",
            "    Uninstalling Markdown-3.1:\n",
            "      Successfully uninstalled Markdown-3.1\n",
            "  Found existing installation: pyparsing 2.4.0\n",
            "    Uninstalling pyparsing-2.4.0:\n",
            "      Successfully uninstalled pyparsing-2.4.0\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: matplotlib 3.0.3\n",
            "    Uninstalling matplotlib-3.0.3:\n",
            "      Successfully uninstalled matplotlib-3.0.3\n",
            "  Found existing installation: pydot 1.3.0\n",
            "    Uninstalling pydot-1.3.0:\n",
            "      Successfully uninstalled pydot-1.3.0\n",
            "  Found existing installation: pydot-ng 2.0.0\n",
            "    Uninstalling pydot-ng-2.0.0:\n",
            "      Successfully uninstalled pydot-ng-2.0.0\n",
            "  Found existing installation: Werkzeug 0.15.2\n",
            "    Uninstalling Werkzeug-0.15.2:\n",
            "      Successfully uninstalled Werkzeug-0.15.2\n",
            "  Found existing installation: tensorboard 1.13.1\n",
            "    Uninstalling tensorboard-1.13.1:\n",
            "      Successfully uninstalled tensorboard-1.13.1\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed Keras-2.1.5 Markdown-2.6.11 PyYAML-3.12 Pygments-2.2.0 Werkzeug-0.14.1 absl-py-0.1.12 appnope-0.1.0 astor-0.6.2 bleach-1.5.0 decorator-4.2.1 gast-0.2.0 graphviz-0.8.2 grpcio-1.10.0 h5py-2.7.1 html5lib-0.9999999 ipykernel-4.8.2 ipython-6.2.1 jedi-0.11.1 jupyter-client-5.2.3 matplotlib-2.2.2 numpy-1.14.2 parso-0.1.1 pexpect-4.4.0 pickleshare-0.7.4 prompt-toolkit-1.0.15 protobuf-3.5.2.post1 ptyprocess-0.5.2 pydot-1.2.4 pydot-ng-1.0.0 pyparsing-2.2.0 python-dateutil-2.7.1 pytz-2018.3 scipy-1.0.1 tensorboard-1.6.0 tensorflow-1.6.0 tornado-5.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "dateutil",
                  "decorator",
                  "google",
                  "grpc",
                  "ipykernel",
                  "jupyter_client",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pexpect",
                  "pickleshare",
                  "prompt_toolkit",
                  "pygments",
                  "pyparsing",
                  "pytz",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WjMdnRSRnJzz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. First load the core libraries"
      ]
    },
    {
      "metadata": {
        "id": "N1XipB0MqCj6",
        "colab_type": "code",
        "outputId": "3bbedfc9-2c46-4afd-c6e8-34a6fc101f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "%cd ./DeepReinforcementLearning\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepReinforcementLearning\n",
            "agent.py   games\t  loss.py    model.py\t       run.ipynb\n",
            "config.py  initialise.py  main.py    README.md\t       settings.py\n",
            "funcs.py   LICENSE\t  MCTS.py    requirements.txt  utils.py\n",
            "game.py    loggers.py\t  memory.py  run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i6denC5WnF59",
        "colab_type": "code",
        "outputId": "3e72ed49-e218-4fd6-852f-db6b5eca2de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# %matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "from shutil import copyfile\n",
        "import random\n",
        "from importlib import reload\n",
        "\n",
        "\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from game import Game, GameState\n",
        "from agent import Agent\n",
        "from memory import Memory\n",
        "from model import Residual_CNN\n",
        "from funcs import playMatches, playMatchesBetweenVersions\n",
        "\n",
        "import loggers as lg\n",
        "\n",
        "from settings import run_folder, run_archive_folder\n",
        "import initialise\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yBdpLBaZoGSP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Now run this block to start the learning process\n",
        "This block loops for ever, continually learning from new game data.\n",
        "\n",
        "The current best model and memories are saved in the run folder so you can kill the process and restart from the last checkpoint."
      ]
    },
    {
      "metadata": {
        "id": "8ZIZHJldoJHg",
        "colab_type": "code",
        "outputId": "c42853ca-8836-47ea-b264-4be484542e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "lg.logger_main.info('=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*')\n",
        "lg.logger_main.info('=*=*=*=*=*=.      NEW LOG      =*=*=*=*=*')\n",
        "lg.logger_main.info('=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*')\n",
        "\n",
        "env = Game()\n",
        "\n",
        "# If loading an existing neural network, copy the config file to root\n",
        "if initialise.INITIAL_RUN_NUMBER != None:\n",
        "    copyfile(run_archive_folder + env.name + '/run' + str(initialise.INITIAL_RUN_NUMBER).zfill(4) + '/config.py', './config.py')\n",
        "\n",
        "import config\n",
        "\n",
        "######## LOAD MEMORIES IF NECESSARY ########\n",
        "\n",
        "if initialise.INITIAL_MEMORY_VERSION == None:\n",
        "    memory = Memory(config.MEMORY_SIZE)\n",
        "else:\n",
        "    print('LOADING MEMORY VERSION ' + str(initialise.INITIAL_MEMORY_VERSION) + '...')\n",
        "    memory = pickle.load( open( run_archive_folder + env.name + '/run' + str(initialise.INITIAL_RUN_NUMBER).zfill(4) + \"/memory/memory\" + str(initialise.INITIAL_MEMORY_VERSION).zfill(4) + \".p\",   \"rb\" ) )\n",
        "\n",
        "######## LOAD MODEL IF NECESSARY ########\n",
        "\n",
        "# create an untrained neural network objects from the config file\n",
        "current_NN = Residual_CNN(config.REG_CONST, config.LEARNING_RATE, (2,) + env.grid_shape,   env.action_size, config.HIDDEN_CNN_LAYERS)\n",
        "best_NN = Residual_CNN(config.REG_CONST, config.LEARNING_RATE, (2,) +  env.grid_shape,   env.action_size, config.HIDDEN_CNN_LAYERS)\n",
        "\n",
        "#If loading an existing neural netwrok, set the weights from that model\n",
        "if initialise.INITIAL_MODEL_VERSION != None:\n",
        "    best_player_version  = initialise.INITIAL_MODEL_VERSION\n",
        "    print('LOADING MODEL VERSION ' + str(initialise.INITIAL_MODEL_VERSION) + '...')\n",
        "    m_tmp = best_NN.read(env.name, initialise.INITIAL_RUN_NUMBER, best_player_version)\n",
        "    current_NN.model.set_weights(m_tmp.get_weights())\n",
        "    best_NN.model.set_weights(m_tmp.get_weights())\n",
        "#otherwise just ensure the weights on the two players are the same\n",
        "else:\n",
        "    best_player_version = 0\n",
        "    best_NN.model.set_weights(current_NN.model.get_weights())\n",
        "\n",
        "#copy the config file to the run folder\n",
        "copyfile('./config.py', run_folder + 'config.py')\n",
        "plot_model(current_NN.model, to_file=run_folder + 'models/model.png', show_shapes = True)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "######## CREATE THE PLAYERS ########\n",
        "\n",
        "current_player = Agent('current_player', env.state_size, env.action_size, config.MCTS_SIMS, config.CPUCT, current_NN)\n",
        "best_player = Agent('best_player', env.state_size, env.action_size, config.MCTS_SIMS, config.CPUCT, best_NN)\n",
        "#user_player = User('player1', env.state_size, env.action_size)\n",
        "iteration = 0\n",
        "\n",
        "while 1:\n",
        "\n",
        "    iteration += 1\n",
        "    reload(lg)\n",
        "    reload(config)\n",
        "    \n",
        "    print('ITERATION NUMBER ' + str(iteration))\n",
        "    \n",
        "    lg.logger_main.info('BEST PLAYER VERSION: %d', best_player_version)\n",
        "    print('BEST PLAYER VERSION ' + str(best_player_version))\n",
        "\n",
        "    ######## SELF PLAY ########\n",
        "    print('SELF PLAYING ' + str(config.EPISODES) + ' EPISODES...')\n",
        "    _, memory, _, _ = playMatches(best_player, best_player, config.EPISODES, lg.logger_main, turns_until_tau0 = config.TURNS_UNTIL_TAU0, memory = memory)\n",
        "    print('\\n')\n",
        "    \n",
        "    memory.clear_stmemory()\n",
        "    \n",
        "    if len(memory.ltmemory) >= config.MEMORY_SIZE:\n",
        "\n",
        "        ######## RETRAINING ########\n",
        "        print('RETRAINING...')\n",
        "        current_player.replay(memory.ltmemory)\n",
        "        print('')\n",
        "\n",
        "        if iteration % 5 == 0:\n",
        "            pickle.dump( memory, open( run_folder + \"memory/memory\" + str(iteration).zfill(4) + \".p\", \"wb\" ) )\n",
        "\n",
        "        lg.logger_memory.info('====================')\n",
        "        lg.logger_memory.info('NEW MEMORIES')\n",
        "        lg.logger_memory.info('====================')\n",
        "        \n",
        "        memory_samp = random.sample(memory.ltmemory, min(1000, len(memory.ltmemory)))\n",
        "        \n",
        "        for s in memory_samp:\n",
        "            current_value, current_probs, _ = current_player.get_preds(s['state'])\n",
        "            best_value, best_probs, _ = best_player.get_preds(s['state'])\n",
        "\n",
        "            lg.logger_memory.info('MCTS VALUE FOR %s: %f', s['playerTurn'], s['value'])\n",
        "            lg.logger_memory.info('CUR PRED VALUE FOR %s: %f', s['playerTurn'], current_value)\n",
        "            lg.logger_memory.info('BES PRED VALUE FOR %s: %f', s['playerTurn'], best_value)\n",
        "            lg.logger_memory.info('THE MCTS ACTION VALUES: %s', ['%.2f' % elem for elem in s['AV']]  )\n",
        "            lg.logger_memory.info('CUR PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  current_probs])\n",
        "            lg.logger_memory.info('BES PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  best_probs])\n",
        "            lg.logger_memory.info('ID: %s', s['state'].id)\n",
        "            lg.logger_memory.info('INPUT TO MODEL: %s', current_player.model.convertToModelInput(s['state']))\n",
        "\n",
        "            s['state'].render(lg.logger_memory)\n",
        "            \n",
        "        ######## TOURNAMENT ########\n",
        "        print('TOURNAMENT...')\n",
        "        scores, _, points, sp_scores = playMatches(best_player, current_player, config.EVAL_EPISODES, lg.logger_tourney, turns_until_tau0 = 0, memory = None)\n",
        "        print('\\nSCORES')\n",
        "        print(scores)\n",
        "        print('\\nSTARTING PLAYER / NON-STARTING PLAYER SCORES')\n",
        "        print(sp_scores)\n",
        "        #print(points)\n",
        "\n",
        "        print('\\n\\n')\n",
        "\n",
        "        if scores['current_player'] > scores['best_player'] * config.SCORING_THRESHOLD:\n",
        "            best_player_version = best_player_version + 1\n",
        "            best_NN.model.set_weights(current_NN.model.get_weights())\n",
        "            best_NN.write(env.name, best_player_version)\n",
        "\n",
        "    else:\n",
        "        print('MEMORY SIZE: ' + str(len(memory.ltmemory)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/DeepReinforcementLearning/loss.py:15: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n",
            "\n",
            "\n",
            "ITERATION NUMBER 1\n",
            "BEST PLAYER VERSION 0\n",
            "SELF PLAYING 30 EPISODES...\n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \n",
            "\n",
            "MEMORY SIZE: 1576\n",
            "ITERATION NUMBER 2\n",
            "BEST PLAYER VERSION 0\n",
            "SELF PLAYING 30 EPISODES...\n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jI0HD6aaoMfn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## The following panels are not involved in the learning process¶\n",
        "### Play matches between versions (use -1 for human player"
      ]
    },
    {
      "metadata": {
        "id": "iGZrCBK-oPuK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from game import Game\n",
        "from funcs import playMatchesBetweenVersions\n",
        "import loggers as lg\n",
        "\n",
        "env = Game()\n",
        "playMatchesBetweenVersions(env, 1, 1, 1, 10, lg.logger_tourney, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KylVyai5oUc_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pass a particular game state through the neural network (setup below for Connect4)\n"
      ]
    },
    {
      "metadata": {
        "id": "7dWaDRW8oW_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gs = GameState(np.array([\n",
        "    0,0,0,0,0,0,0,\n",
        "    0,0,0,0,0,0,0,\n",
        "    0,0,0,0,0,0,0,\n",
        "    0,0,0,0,0,0,0,\n",
        "    0,0,0,0,0,0,0,\n",
        "    0,0,0,0,0,0,0\n",
        "]), 1)\n",
        "\n",
        "preds = current_player.get_preds(gs)\n",
        "\n",
        "print(preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AQEqnbSXoZI5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### See the layers of the current neural network"
      ]
    },
    {
      "metadata": {
        "id": "4SSaMiHqoaxh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "current_player.model.viewLayers()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5lZ8Lxhyod2a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Output a diagram of the neural network architecture"
      ]
    },
    {
      "metadata": {
        "id": "8qxvf7P1ogVv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(current_NN.model, to_file=run_folder + 'models/model.png', show_shapes = True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}